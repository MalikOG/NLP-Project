{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee81e187",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ee8c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b9a4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7130"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_balanced = pd.read_pickle('train_balanced.pkl')\n",
    "val_balanced = pd.read_pickle('val_balanced.pkl')\n",
    "test_balanced = pd.read_pickle('test_balanced.pkl')\n",
    "VOCAB_BALANCED_SIZE = set()\n",
    "for tokenized in train_balanced.tokenized:\n",
    "    for token in tokenized:\n",
    "        VOCAB_BALANCED_SIZE.add(token)\n",
    "max(VOCAB_BALANCED_SIZE)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe671d4-6fc7-47aa-82b3-cdae4bc46475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6767"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_unbalanced = pd.read_pickle('train_unbalanced.pkl')\n",
    "val_unbalanced = pd.read_pickle('val_unbalanced.pkl')\n",
    "test_unbalanced = pd.read_pickle('test_unbalanced.pkl')\n",
    "\n",
    "VOCAB_UNBALANCED_SIZE = set()\n",
    "for tokenized in train_unbalanced.tokenized:\n",
    "    for token in tokenized:\n",
    "        VOCAB_UNBALANCED_SIZE.add(token)\n",
    "\n",
    "max(VOCAB_UNBALANCED_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cc4393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, data, X, y):\n",
    "        self.X = data[X]\n",
    "        self.y = data[y]\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float), torch.tensor(self.y[idx], dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cde3550-8bb4-48d4-96dd-34130d3a0a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unbalanced=np.stack(train_unbalanced['MultiLabel'].to_numpy())\n",
    "y_balanced=np.stack(train_balanced['MultiLabel'].to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8005d478-a233-4db6-9165-67325bc81c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_embed_balanced = ClassificationDataset(train_balanced, \"precomputed_embeddings\", \"MultiLabel\")\n",
    "val_dataset_embed_balanced = ClassificationDataset(val_balanced, \"precomputed_embeddings\", \"MultiLabel\")\n",
    "test_dataset_embed_balanced= ClassificationDataset(test_balanced, \"precomputed_embeddings\", \"MultiLabel\")\n",
    "\n",
    "train_loader_balanced = DataLoader(train_dataset_embed_balanced, batch_size=16, shuffle=True)\n",
    "val_loader_balanced = DataLoader(val_dataset_embed_balanced, batch_size=16, shuffle=False)\n",
    "test_loader_balanced = DataLoader(test_dataset_embed_balanced, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f5f2d97-45b2-4519-8cd3-f330c5fdf2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_embed_unbalanced = ClassificationDataset(train_unbalanced, \"precomputed_embeddings\", \"MultiLabel\")\n",
    "val_dataset_embed_unbalanced = ClassificationDataset(val_unbalanced, \"precomputed_embeddings\", \"MultiLabel\")\n",
    "test_dataset_embed_unbalanced= ClassificationDataset(test_unbalanced, \"precomputed_embeddings\", \"MultiLabel\")\n",
    "\n",
    "train_loader_unbalanced = DataLoader(train_dataset_embed_unbalanced, batch_size=16, shuffle=True)\n",
    "val_loader_unbalanced = DataLoader(val_dataset_embed_unbalanced, batch_size=16, shuffle=False)\n",
    "test_loader_unbalanced = DataLoader(test_dataset_embed_unbalanced, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a366cfc3",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a004bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.functional import F\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b61d2384",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelLSTM(nn.Module):\n",
    "    def __init__(self,\n",
    "              vocab_size,\n",
    "              embedding_dim,\n",
    "              hidden_dim,\n",
    "              num_layers,\n",
    "              num_classes,\n",
    "              bidirectional,\n",
    "              dropout,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # LSTM Layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, bidirectional=bidirectional, dropout=dropout)\n",
    "        # Linear Layer\n",
    "        if bidirectional:\n",
    "            self.linear = nn.Linear(hidden_dim * 2, num_classes)\n",
    "        else:\n",
    "            self.linear = nn.Linear(hidden_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        linear = self.linear(lstm_out)\n",
    "        return linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad854295-59d8-4dde-8db8-86d25bed83b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May 10 21:39:29 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.133.07             Driver Version: 572.83         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     On  |   00000000:01:00.0  On |                  N/A |\n",
      "| 31%   41C    P2             74W /  260W |    1269MiB /  11264MiB |     27%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A              26      G   /Xwayland                             N/A      |\n",
      "|    0   N/A  N/A            8437      C   /ollama                               N/A      |\n",
      "|    0   N/A  N/A            9450      C   /python3.10                           N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd637ba",
   "metadata": {},
   "source": [
    "# Train & Validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ad75936-1991-467f-a310-810e116dbadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import itertools\n",
    "from torch.nn.functional import sigmoid\n",
    "from tqdm import tqdm\n",
    "from torcheval.metrics.functional import multiclass_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2580019f-969f-4a29-8eb9-858f8d650d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(row):\n",
    "    row = sigmoid(torch.tensor(row))\n",
    "    row[row >=0.5] = 1\n",
    "    row[row <0.5] = 0\n",
    "    row.numpy().astype(np.float32)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57b4819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for weighted loss\n",
    "pos_weight_balanced = (y_balanced.shape[0] - y_balanced.sum(axis=0)) / (y_balanced.sum(axis=0) + 0.0000001)\n",
    "pos_weight_balanced = torch.tensor(pos_weight_balanced, dtype=torch.float32).to(\"cuda\")  # or your device\n",
    "\n",
    "def objective_balanced(trial, epochs=3):\n",
    "    # Hyperparameter search space\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    embedding_dim = trial.suggest_categorical(\"embedding_dim\", [768])\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [64, 128, 256, 512])\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 2, 5, step=1)\n",
    "    bidirectional = trial.suggest_categorical(\"bidirectional\", [True, False])\n",
    "    dropout = trial.suggest_categorical(\"dropout\", [0.1, 0.25, 0.5])\n",
    "    NUM_CLASSES = 4\n",
    "    MAX_LEN = 1\n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    model = MultiLabelLSTM(\n",
    "        vocab_size=max(VOCAB_BALANCED_SIZE),\n",
    "        embedding_dim=embedding_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        bidirectional=bidirectional,\n",
    "        dropout=dropout,\n",
    "    ).to(DEVICE)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_balanced)\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "\t\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for X_batch, y_batch in train_loader_balanced:\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            y_preds = model(X_batch)\n",
    "            loss = criterion(y_preds, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    y_preds_list = []\n",
    "    y_true_list = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader_balanced:\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "            y_preds = model(X_batch)\n",
    "            y_preds_list.extend(y_preds.detach().cpu().numpy())\n",
    "            y_true_list.extend(y_batch.detach().cpu().numpy())\n",
    "    y_preds = np.array([get_prediction(pred) for pred in y_preds_list])\n",
    "    y_true = np.array(y_true_list)\n",
    "\n",
    "    f1 = f1_score(y_true, y_preds, average='weighted')\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae622d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 21:43:37,493] A new study created in memory with name: no-name-2f61b9aa-b4ac-4ee9-b0d6-cd4cca40d780\n",
      "[I 2025-05-10 21:43:40,365] Trial 0 finished with value: 0.712322495675605 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 4, 'bidirectional': True, 'dropout': 0.1, 'lr': 0.0009879073621631908}. Best is trial 0 with value: 0.712322495675605.\n",
      "[I 2025-05-10 21:43:42,061] Trial 1 finished with value: 0.7022927433959593 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 4, 'bidirectional': False, 'dropout': 0.1, 'lr': 0.0012843821699711861}. Best is trial 0 with value: 0.712322495675605.\n",
      "[I 2025-05-10 21:43:44,250] Trial 2 finished with value: 0.6284817088860427 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 5, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.002404467085282438}. Best is trial 0 with value: 0.712322495675605.\n",
      "[I 2025-05-10 21:43:46,464] Trial 3 finished with value: 0.7409870341410524 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 3, 'bidirectional': False, 'dropout': 0.1, 'lr': 0.0007530160551745292}. Best is trial 3 with value: 0.7409870341410524.\n",
      "[I 2025-05-10 21:43:48,426] Trial 4 finished with value: 0.6306572049652966 and parameters: {'embedding_dim': 768, 'hidden_dim': 64, 'num_layers': 5, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.003916263264588941}. Best is trial 3 with value: 0.7409870341410524.\n",
      "[I 2025-05-10 21:43:50,954] Trial 5 finished with value: 0.7160259504669043 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0007406681658567014}. Best is trial 3 with value: 0.7409870341410524.\n",
      "[I 2025-05-10 21:43:52,921] Trial 6 finished with value: 0.7285623424282975 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.001785453437341482}. Best is trial 3 with value: 0.7409870341410524.\n",
      "[I 2025-05-10 21:43:54,428] Trial 7 finished with value: 0.741550029242584 and parameters: {'embedding_dim': 768, 'hidden_dim': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.1, 'lr': 0.000522391372925673}. Best is trial 7 with value: 0.741550029242584.\n",
      "[I 2025-05-10 21:43:57,261] Trial 8 finished with value: 0.6544483767900733 and parameters: {'embedding_dim': 768, 'hidden_dim': 64, 'num_layers': 5, 'bidirectional': True, 'dropout': 0.5, 'lr': 0.008345672616771374}. Best is trial 7 with value: 0.741550029242584.\n",
      "[I 2025-05-10 21:44:00,075] Trial 9 finished with value: 0.6227023278031303 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.00011172833002387459}. Best is trial 7 with value: 0.741550029242584.\n",
      "[I 2025-05-10 21:44:03,358] Trial 10 finished with value: 0.7558023688409854 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.1, 'lr': 0.00024426911904814697}. Best is trial 10 with value: 0.7558023688409854.\n",
      "[I 2025-05-10 21:44:06,379] Trial 11 finished with value: 0.7508813875019178 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.1, 'lr': 0.00023277570057227254}. Best is trial 10 with value: 0.7558023688409854.\n",
      "[I 2025-05-10 21:44:09,460] Trial 12 finished with value: 0.7586486629824128 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.1, 'lr': 0.0002049173817318604}. Best is trial 12 with value: 0.7586486629824128.\n",
      "[I 2025-05-10 21:44:13,613] Trial 13 finished with value: 0.7365428751020249 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.1, 'lr': 0.00022891105343513071}. Best is trial 12 with value: 0.7586486629824128.\n",
      "[I 2025-05-10 21:44:17,656] Trial 14 finished with value: 0.7472789324835605 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.1, 'lr': 0.0003061315055006012}. Best is trial 12 with value: 0.7586486629824128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.1, 'lr': 0.0002049173817318604}\n"
     ]
    }
   ],
   "source": [
    "# ---- Run the Optuna Study ----\n",
    "study_balanced = optuna.create_study(direction=\"maximize\")\n",
    "study_balanced.optimize(objective_balanced, n_trials=15)\n",
    "\n",
    "print(\"Best hyperparameters:\", study_balanced.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4bbf831-1bf6-4e60-a378-ec6af47de63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for weighted loss\n",
    "pos_weight_unbalanced = (y_unbalanced.shape[0] - y_unbalanced.sum(axis=0)) / (y_balanced.sum(axis=0) + 0.0000001)\n",
    "pos_weight_unbalanced = torch.tensor(pos_weight_unbalanced, dtype=torch.float32).to(\"cuda\")  # or your device\n",
    "\n",
    "def objective_unbalanced(trial, epochs=3):\n",
    "    # Hyperparameter search space\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    embedding_dim = trial.suggest_categorical(\"embedding_dim\", [768])\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [64, 128, 256, 512])\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 2, 5, step=1)\n",
    "    bidirectional = trial.suggest_categorical(\"bidirectional\", [True, False])\n",
    "    dropout = trial.suggest_categorical(\"dropout\", [0.1, 0.25, 0.5])\n",
    "    NUM_CLASSES = 4\n",
    "    MAX_LEN = 1\n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    model = MultiLabelLSTM(\n",
    "        vocab_size=len(VOCAB_UNBALANCED_SIZE) + 1000,\n",
    "        embedding_dim=embedding_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        bidirectional=bidirectional,\n",
    "        dropout=dropout,\n",
    "    ).to(DEVICE)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_unbalanced)\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "\t\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for X_batch, y_batch in train_loader_unbalanced:\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            y_preds = model(X_batch)\n",
    "            loss = criterion(y_preds, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    y_preds_list = []\n",
    "    y_true_list = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader_unbalanced:\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "            y_preds = model(X_batch)\n",
    "            y_preds_list.extend(y_preds.detach().cpu().numpy())\n",
    "            y_true_list.extend(y_batch.detach().cpu().numpy())\n",
    "    y_preds = np.array([get_prediction(pred) for pred in y_preds_list])\n",
    "    y_true = np.array(y_true_list)\n",
    "\n",
    "    f1 = f1_score(y_true, y_preds, average='weighted')\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98d60c00-60f2-42ae-8091-3fc1c25706e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 21:48:35,220] A new study created in memory with name: no-name-8ef45d91-19f6-4a7b-999e-0a2c3713ec96\n",
      "[I 2025-05-10 21:48:38,025] Trial 0 finished with value: 0.6116827073281391 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0.5, 'lr': 0.0023946223363255693}. Best is trial 0 with value: 0.6116827073281391.\n",
      "[I 2025-05-10 21:48:40,125] Trial 1 finished with value: 0.5622926518168503 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 4, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.004538281873184708}. Best is trial 0 with value: 0.6116827073281391.\n",
      "[I 2025-05-10 21:48:41,354] Trial 2 finished with value: 0.5642724934059048 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 4, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.0003255612117100354}. Best is trial 0 with value: 0.6116827073281391.\n",
      "[I 2025-05-10 21:48:42,986] Trial 3 finished with value: 0.6831403170613638 and parameters: {'embedding_dim': 768, 'hidden_dim': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0029017581406785464}. Best is trial 3 with value: 0.6831403170613638.\n",
      "[I 2025-05-10 21:48:44,927] Trial 4 finished with value: 0.6234246747777408 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 5, 'bidirectional': True, 'dropout': 0.5, 'lr': 0.0018059624988412707}. Best is trial 3 with value: 0.6831403170613638.\n",
      "[I 2025-05-10 21:48:46,698] Trial 5 finished with value: 0.6826048823269699 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 3, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.006404352308507077}. Best is trial 3 with value: 0.6831403170613638.\n",
      "[I 2025-05-10 21:48:48,048] Trial 6 finished with value: 0.7344628047148495 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.5, 'lr': 0.005029850624851886}. Best is trial 6 with value: 0.7344628047148495.\n",
      "[I 2025-05-10 21:48:49,861] Trial 7 finished with value: 0.7374224657100104 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.00012351401217085365}. Best is trial 7 with value: 0.7374224657100104.\n",
      "[I 2025-05-10 21:48:51,658] Trial 8 finished with value: 0.6957237107363349 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 3, 'bidirectional': False, 'dropout': 0.1, 'lr': 0.00015128253940434392}. Best is trial 7 with value: 0.7374224657100104.\n",
      "[I 2025-05-10 21:48:53,874] Trial 9 finished with value: 0.7414046930539321 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.1, 'lr': 0.00013902936913639516}. Best is trial 9 with value: 0.7414046930539321.\n",
      "[I 2025-05-10 21:48:57,168] Trial 10 finished with value: 0.6441502931392719 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 5, 'bidirectional': True, 'dropout': 0.1, 'lr': 0.0005820658656937324}. Best is trial 9 with value: 0.7414046930539321.\n",
      "[I 2025-05-10 21:48:59,002] Trial 11 finished with value: 0.7210300061904141 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.1, 'lr': 0.00010599957447062303}. Best is trial 9 with value: 0.7414046930539321.\n",
      "[I 2025-05-10 21:49:00,787] Trial 12 finished with value: 0.7557775969959317 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.00025457032231386887}. Best is trial 12 with value: 0.7557775969959317.\n",
      "[I 2025-05-10 21:49:02,994] Trial 13 finished with value: 0.7344862886984198 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.1, 'lr': 0.0002852795239366178}. Best is trial 12 with value: 0.7557775969959317.\n",
      "[I 2025-05-10 21:49:04,290] Trial 14 finished with value: 0.7386992920648694 and parameters: {'embedding_dim': 768, 'hidden_dim': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.000815619414194414}. Best is trial 12 with value: 0.7557775969959317.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.00025457032231386887}\n"
     ]
    }
   ],
   "source": [
    "# ---- Run the Optuna Study ----\n",
    "study_unbalanced = optuna.create_study(direction=\"maximize\")\n",
    "study_unbalanced.optimize(objective_unbalanced, n_trials=15)\n",
    "\n",
    "print(\"Best hyperparameters:\", study_unbalanced.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8dcc2d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val(\n",
    "        model: MultiLabelLSTM,\n",
    "        optim: Adam,\n",
    "        criterion: nn.BCEWithLogitsLoss,\n",
    "        epochs: int,\n",
    "        train_dataloader: DataLoader,\n",
    "        val_dataloader: DataLoader,\n",
    "        device\n",
    "    ):\n",
    "    best_f1 = 0\n",
    "    best_model = None\n",
    "    model.to(device)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        y_preds_list_train = []\n",
    "        y_true_list_train = []\n",
    "        for train_X, train_y in train_dataloader:\n",
    "            train_X, train_y = train_X.to(device), train_y.to(device)\n",
    "    \n",
    "            y_preds = model(train_X)\n",
    "            loss = criterion(y_preds, train_y)\n",
    "    \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "    \n",
    "            train_loss += loss.item()\n",
    "            y_preds_list_train.extend(y_preds.detach().cpu().numpy())\n",
    "            y_true_list_train.extend(train_y.detach().cpu().numpy())\n",
    "    \n",
    "        y_preds = np.array([get_prediction(pred) for pred in y_preds_list_train])\n",
    "        y_true = np.array(y_true_list_train) \n",
    "        train_f1 =f1_score(y_true, y_preds, average='weighted')\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        y_preds_list_val = []\n",
    "        y_true_list_val = []\n",
    "        with torch.no_grad():\n",
    "            for val_X, val_y in val_dataloader:\n",
    "                val_X, val_y = val_X.to(device), val_y.to(device)\n",
    "    \n",
    "                y_preds = model(val_X)\n",
    "                loss = criterion(y_preds, val_y)\n",
    "                val_loss += loss.item()\n",
    "                predicted = torch.argmax(y_preds, dim=1)\n",
    "                y_preds_list_val.extend(y_preds.detach().cpu().numpy())\n",
    "                y_true_list_val.extend(val_y.detach().cpu().numpy())\n",
    "    \n",
    "        y_preds = np.array([get_prediction(pred) for pred in y_preds_list_val])\n",
    "        y_true = np.array(y_true_list_val)\n",
    "        val_f1 = f1_score(y_true, y_preds, average='weighted')\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_model = model.state_dict()\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs}, \"\n",
    "            f\"Train Loss: {train_loss/len(train_dataloader):.4f}, \"\n",
    "            f\"Val Loss: {val_loss/len(val_dataloader):.4f}, \"\n",
    "            f\"Train F1: {train_f1:.2f}%, \"\n",
    "            f\"Val F1: {val_f1:.2f}%\"\n",
    "        )\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9541a4a-d5d7-415d-9ba6-d2e86037b461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▍                                                                           | 1/10 [00:01<00:12,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.6984, Val Loss: 0.5882, Train F1: 0.60%, Val F1: 0.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 2/10 [00:02<00:11,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.5880, Val Loss: 0.5404, Train F1: 0.69%, Val F1: 0.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▏                                                          | 3/10 [00:04<00:09,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.5334, Val Loss: 0.5319, Train F1: 0.73%, Val F1: 0.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▌                                                  | 4/10 [00:05<00:08,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.4840, Val Loss: 0.5694, Train F1: 0.76%, Val F1: 0.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████                                          | 5/10 [00:07<00:07,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.4358, Val Loss: 0.5844, Train F1: 0.78%, Val F1: 0.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████▍                                 | 6/10 [00:08<00:05,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.3782, Val Loss: 0.6605, Train F1: 0.81%, Val F1: 0.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████▊                         | 7/10 [00:09<00:04,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.3259, Val Loss: 0.7773, Train F1: 0.84%, Val F1: 0.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████▏                | 8/10 [00:11<00:02,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.2852, Val Loss: 0.7854, Train F1: 0.86%, Val F1: 0.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████████▌        | 9/10 [00:12<00:01,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.2501, Val Loss: 0.9017, Train F1: 0.87%, Val F1: 0.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:14<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.2193, Val Loss: 1.0310, Train F1: 0.89%, Val F1: 0.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_balanced = MultiLabelLSTM(\n",
    "\t\t\tvocab_size=len(VOCAB_BALANCED_SIZE),\n",
    "\t\t\tembedding_dim=study_balanced.best_trial.params['embedding_dim'],\n",
    "\t\t\thidden_dim=study_balanced.best_trial.params['hidden_dim'],\n",
    "\t\t\tnum_layers=study_balanced.best_trial.params['num_layers'],\n",
    "\t\t\tnum_classes=4,\n",
    "\t\t\tbidirectional=study_balanced.best_trial.params['bidirectional'],\n",
    "            dropout = study_balanced.best_trial.params['dropout'],\n",
    "\t\t).to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_balanced)\n",
    "optimizer_balanced = Adam(model_balanced.parameters(), lr=study_balanced.best_trial.params['lr'])\n",
    "params_balanced = train_val(\n",
    "    model_balanced,\n",
    "    optimizer_balanced,\n",
    "    criterion,\n",
    "    epochs = 10,\n",
    "    train_dataloader = train_loader_balanced,\n",
    "    val_dataloader = val_loader_balanced,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9373590e-221e-4d4d-a197-72df5135ec5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▍                                                                           | 1/10 [00:00<00:06,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.6701, Val Loss: 0.6719, Train F1: 0.42%, Val F1: 0.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 2/10 [00:01<00:06,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.6705, Val Loss: 0.6719, Train F1: 0.42%, Val F1: 0.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▏                                                          | 3/10 [00:02<00:05,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.6706, Val Loss: 0.6719, Train F1: 0.42%, Val F1: 0.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▌                                                  | 4/10 [00:02<00:04,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.6704, Val Loss: 0.6719, Train F1: 0.43%, Val F1: 0.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████                                          | 5/10 [00:03<00:03,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.6702, Val Loss: 0.6719, Train F1: 0.42%, Val F1: 0.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████▍                                 | 6/10 [00:04<00:02,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.6705, Val Loss: 0.6719, Train F1: 0.43%, Val F1: 0.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████▊                         | 7/10 [00:05<00:02,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.6706, Val Loss: 0.6719, Train F1: 0.43%, Val F1: 0.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████▏                | 8/10 [00:05<00:01,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.6709, Val Loss: 0.6719, Train F1: 0.42%, Val F1: 0.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████████▌        | 9/10 [00:06<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.6701, Val Loss: 0.6719, Train F1: 0.43%, Val F1: 0.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.6702, Val Loss: 0.6719, Train F1: 0.42%, Val F1: 0.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_unbalanced = MultiLabelLSTM(\n",
    "\t\t\tvocab_size=len(VOCAB_UNBALANCED_SIZE)+1000,\n",
    "\t\t\tembedding_dim=study_unbalanced.best_trial.params['embedding_dim'],\n",
    "\t\t\thidden_dim=study_unbalanced.best_trial.params['hidden_dim'],\n",
    "\t\t\tnum_layers=study_unbalanced.best_trial.params['num_layers'],\n",
    "\t\t\tnum_classes=4,\n",
    "\t\t\tbidirectional=study_unbalanced.best_trial.params['bidirectional'],\n",
    "            dropout = study_unbalanced.best_trial.params['dropout'],\n",
    "\t\t).to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_unbalanced)\n",
    "optimizer_unbalanced = Adam(model_balanced.parameters(), lr=study_unbalanced.best_trial.params['lr'])\n",
    "params_unbalanced = train_val(\n",
    "    model_unbalanced,\n",
    "    optimizer_unbalanced,\n",
    "    criterion,\n",
    "    epochs = 10,\n",
    "    train_dataloader = train_loader_unbalanced,\n",
    "    val_dataloader = val_loader_unbalanced,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6c1dfb",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad40d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8363a59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(\n",
    "\t\tmodel: MultiLabelLSTM,\n",
    "\t\tcriterion: nn.BCEWithLogitsLoss,\n",
    "\t\ttest_dataloader: DataLoader,\n",
    "\t\tdevice\n",
    "    ):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    y_preds_list = []\n",
    "    y_true_list = []\n",
    "    with torch.no_grad():\n",
    "        for test_X, test_y in test_dataloader:\n",
    "            test_X, test_y = test_X.to(device), test_y.to(device)\n",
    "    \n",
    "            y_preds = model(test_X)\n",
    "            y_preds_list.extend(y_preds.detach().cpu().numpy())\n",
    "            y_true_list.extend(test_y.detach().cpu().numpy())\n",
    "            loss = criterion(y_preds, test_y)\n",
    "            test_loss += loss.item()\n",
    "        \n",
    "        y_preds_list = [get_prediction(pred) for pred in y_preds_list]\n",
    "    print(\n",
    "        f\"test Loss: {test_loss/len(test_dataloader):.4f}, \"\n",
    "        f\"test Acc: {accuracy_score(y_true_list, y_preds_list)}%\"\n",
    "    )\n",
    "    return np.array(y_preds_list), np.array(y_true_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2062a37-dc61-4be2-b78f-516012a82ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.0777, test Acc: 0.39928698752228164%\n"
     ]
    }
   ],
   "source": [
    "best_model_balanced = MultiLabelLSTM(\n",
    "\t\t\tvocab_size=len(VOCAB_BALANCED_SIZE),\n",
    "\t\t\tembedding_dim=study_balanced.best_trial.params['embedding_dim'],\n",
    "\t\t\thidden_dim=study_balanced.best_trial.params['hidden_dim'],\n",
    "\t\t\tnum_layers=study_balanced.best_trial.params['num_layers'],\n",
    "\t\t\tnum_classes=4,\n",
    "\t\t\tbidirectional=study_balanced.best_trial.params['bidirectional'],\n",
    "            dropout = study_balanced.best_trial.params['dropout'],\n",
    "\t\t).to(DEVICE)\n",
    "best_model_balanced.load_state_dict(params_balanced)\n",
    "y_preds, y_true=testing(best_model_balanced, criterion, test_loader_balanced, 'cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f20b4119-a30e-4f2c-ac7e-597966e4e8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79       229\n",
      "           1       0.63      0.59      0.61       215\n",
      "           2       0.84      0.83      0.84       387\n",
      "           3       0.57      0.44      0.50       151\n",
      "\n",
      "   micro avg       0.75      0.71      0.73       982\n",
      "   macro avg       0.71      0.66      0.68       982\n",
      "weighted avg       0.74      0.71      0.72       982\n",
      " samples avg       0.79      0.77      0.74       982\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malik/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[280,  52],\n",
       "        [ 47, 182]],\n",
       "\n",
       "       [[273,  73],\n",
       "        [ 89, 126]],\n",
       "\n",
       "       [[113,  61],\n",
       "        [ 65, 322]],\n",
       "\n",
       "       [[361,  49],\n",
       "        [ 85,  66]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_true=y_true, y_pred=y_preds))\n",
    "print(multilabel_confusion_matrix(y_true=y_true, y_pred=y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3b4e587-bb8f-4531-93db-3a39b50a3666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.7670, test Acc: 0.03208556149732621%\n"
     ]
    }
   ],
   "source": [
    "best_model_unbalanced = MultiLabelLSTM(\n",
    "\t\t\tvocab_size=len(VOCAB_UNBALANCED_SIZE)+1000,\n",
    "\t\t\tembedding_dim=study_unbalanced.best_trial.params['embedding_dim'],\n",
    "\t\t\thidden_dim=study_unbalanced.best_trial.params['hidden_dim'],\n",
    "\t\t\tnum_layers=study_unbalanced.best_trial.params['num_layers'],\n",
    "\t\t\tnum_classes=4,\n",
    "\t\t\tbidirectional=study_unbalanced.best_trial.params['bidirectional'],\n",
    "            dropout = study_unbalanced.best_trial.params['dropout'],\n",
    "\t\t).to(DEVICE)\n",
    "best_model_unbalanced.load_state_dict(params_unbalanced)\n",
    "y_preds, y_true=testing(best_model_unbalanced, criterion, test_loader_unbalanced, 'cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ca433bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.14      0.22       229\n",
      "           1       0.39      0.73      0.51       215\n",
      "           2       0.71      0.29      0.41       387\n",
      "           3       0.25      0.67      0.36       151\n",
      "\n",
      "   micro avg       0.39      0.41      0.40       982\n",
      "   macro avg       0.46      0.46      0.37       982\n",
      "weighted avg       0.52      0.41      0.38       982\n",
      " samples avg       0.35      0.40      0.34       982\n",
      "\n",
      "[[[298  34]\n",
      "  [197  32]]\n",
      "\n",
      " [[101 245]\n",
      "  [ 59 156]]\n",
      "\n",
      " [[128  46]\n",
      "  [275 112]]\n",
      "\n",
      " [[104 306]\n",
      "  [ 50 101]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malik/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_true, y_pred=y_preds))\n",
    "print(multilabel_confusion_matrix(y_true=y_true, y_pred=y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e316a2-4afc-42d2-91b8-fe1088aff279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
