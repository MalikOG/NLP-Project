{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee81e187",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c7ee8c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "94b9a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_pickle('precomputed_embeddings.pkl')\n",
    "y = pd.read_pickle('multilabel.pkl')\n",
    "with open('vocab.txt', 'r') as f:\n",
    "\tvocab = f.read().split(\" \")\n",
    "\tvocab.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ad42f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2784, 2784, 9210)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y), len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "95a66380-8eba-4c8b-aa58-485e97520077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1]], dtype=int32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aa34b9",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "51ebb322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "76122f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=777)\n",
    "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, test_size=0.15, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8339ef43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1892,), (335,), (557,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, val_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b2f7ca5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1892, 4), (335, 4), (557, 4))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape, val_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4cc4393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float), torch.tensor(self.y[idx], dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8005d478-a233-4db6-9165-67325bc81c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ClassificationDataset(train_X, train_y)\n",
    "val_dataset = ClassificationDataset(val_X, val_y)\n",
    "test_dataset = ClassificationDataset(test_X, test_y)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a366cfc3",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0a004bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.functional import F\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b61d2384",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelLSTM(nn.Module):\n",
    "    def __init__(self,\n",
    "              vocab_size,\n",
    "              embedding_dim,\n",
    "              hidden_dim,\n",
    "              num_layers,\n",
    "              num_classes,\n",
    "              bidirectional,\n",
    "              dropout,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # LSTM Layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, bidirectional=bidirectional, dropout=dropout)\n",
    "        # Linear Layer\n",
    "        if bidirectional:\n",
    "            self.linear = nn.Linear(hidden_dim * 2, num_classes)\n",
    "        else:\n",
    "            self.linear = nn.Linear(hidden_dim, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        linear = self.linear(lstm_out)\n",
    "        return self.sigmoid(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd637ba",
   "metadata": {},
   "source": [
    "# Train & Validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2ad75936-1991-467f-a310-810e116dbadf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from torcheval.metrics.functional import multiclass_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2580019f-969f-4a29-8eb9-858f8d650d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(row):\n",
    "    row[row >=0.5] = 1\n",
    "    row[row <0.5] = 0\n",
    "    row.astype(np.float32)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "57b4819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, epochs=3):\n",
    "    # Hyperparameter search space\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    embedding_dim = trial.suggest_categorical(\"embedding_dim\", [768])\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [64, 128, 256, 512])\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 5, step=1)\n",
    "    bidirectional = trial.suggest_categorical(\"bidirectional\", [True, False])\n",
    "    dropout = trial.suggest_categorical(\"dropout\", [0.1, 0.25, 0.5])\n",
    "    VOCAB_SIZE = len(vocab)\n",
    "    NUM_CLASSES = 4\n",
    "    MAX_LEN = 1\n",
    "    # weights = (\n",
    "    #     None if weights_choice is None\n",
    "    #     else torch.tensor(weights_choice).to(DEVICE)\n",
    "    # )\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    model = MultiLabelLSTM(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        embedding_dim=embedding_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        bidirectional=bidirectional,\n",
    "        dropout=dropout,\n",
    "    ).to(DEVICE)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "\t\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            y_preds = model(X_batch)\n",
    "            loss = criterion(y_preds, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    y_preds_list = []\n",
    "    y_true_list = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "            y_preds = model(X_batch)\n",
    "            y_preds_list.extend(y_preds.detach().cpu().numpy())\n",
    "            y_true_list.extend(y_batch.detach().cpu().numpy())\n",
    "    y_preds = np.array([get_prediction(pred) for pred in y_preds_list])\n",
    "    y_true = np.array(y_true_list)\n",
    "\n",
    "    f1 = f1_score(y_true, y_preds, average='weighted')\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ae622d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 23:15:57,676] A new study created in memory with name: no-name-b115b0c0-aa55-4c0e-856a-59fbf45230bf\n",
      "[I 2025-05-09 23:15:59,247] Trial 0 finished with value: 0.6650916317758602 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.00033287359690745496}. Best is trial 0 with value: 0.6650916317758602.\n",
      "[I 2025-05-09 23:16:00,413] Trial 1 finished with value: 0.6644502500430883 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.1, 'lr': 0.003921736302176072}. Best is trial 0 with value: 0.6650916317758602.\n",
      "[I 2025-05-09 23:16:04,056] Trial 2 finished with value: 0.5809203732722411 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 4, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0002526469994742172}. Best is trial 0 with value: 0.6650916317758602.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:04,920] Trial 3 finished with value: 0.658605780620706 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.1, 'lr': 0.0010793717784075632}. Best is trial 0 with value: 0.6650916317758602.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:05,804] Trial 4 finished with value: 0.5836753528135534 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 1, 'bidirectional': True, 'dropout': 0.5, 'lr': 0.0001776451880508168}. Best is trial 0 with value: 0.6650916317758602.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:06,533] Trial 5 finished with value: 0.5178592484562634 and parameters: {'embedding_dim': 768, 'hidden_dim': 64, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.00022074351969321492}. Best is trial 0 with value: 0.6650916317758602.\n",
      "[I 2025-05-09 23:16:07,641] Trial 6 finished with value: 0.41864381794730054 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 4, 'bidirectional': False, 'dropout': 0.1, 'lr': 0.0004156257038815363}. Best is trial 0 with value: 0.6650916317758602.\n",
      "[I 2025-05-09 23:16:08,746] Trial 7 finished with value: 0.0 and parameters: {'embedding_dim': 768, 'hidden_dim': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.000139935100399796}. Best is trial 0 with value: 0.6650916317758602.\n",
      "[I 2025-05-09 23:16:09,804] Trial 8 finished with value: 0.5345947221722712 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 4, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0025760376248297316}. Best is trial 0 with value: 0.6650916317758602.\n",
      "[I 2025-05-09 23:16:11,739] Trial 9 finished with value: 0.5296052631578948 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.1, 'lr': 0.007467945101749546}. Best is trial 0 with value: 0.6650916317758602.\n",
      "[I 2025-05-09 23:16:12,992] Trial 10 finished with value: 0.6649198364914056 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.000740636372319946}. Best is trial 0 with value: 0.6650916317758602.\n",
      "[I 2025-05-09 23:16:14,241] Trial 11 finished with value: 0.6682130566242375 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0007719260412145661}. Best is trial 11 with value: 0.6682130566242375.\n",
      "[I 2025-05-09 23:16:15,507] Trial 12 finished with value: 0.6509004420189569 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0009835958627697455}. Best is trial 11 with value: 0.6682130566242375.\n",
      "[I 2025-05-09 23:16:17,035] Trial 13 finished with value: 0.6522922789872925 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 3, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.00048037399342111986}. Best is trial 11 with value: 0.6682130566242375.\n",
      "[I 2025-05-09 23:16:18,073] Trial 14 finished with value: 0.6533723627850054 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.002351229671990725}. Best is trial 11 with value: 0.6682130566242375.\n",
      "[I 2025-05-09 23:16:20,299] Trial 15 finished with value: 0.28683853459972863 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 5, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0001030669522076547}. Best is trial 11 with value: 0.6682130566242375.\n",
      "[I 2025-05-09 23:16:21,877] Trial 16 finished with value: 0.6326051798285022 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 3, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.000443614400550368}. Best is trial 11 with value: 0.6682130566242375.\n",
      "[I 2025-05-09 23:16:23,180] Trial 17 finished with value: 0.6550063719535424 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0016247455022302445}. Best is trial 11 with value: 0.6682130566242375.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:24,222] Trial 18 finished with value: 0.6550216556498252 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 1, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0003133304368957763}. Best is trial 11 with value: 0.6682130566242375.\n",
      "[I 2025-05-09 23:16:25,023] Trial 19 finished with value: 0.5512653453139644 and parameters: {'embedding_dim': 768, 'hidden_dim': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.0007712812720027511}. Best is trial 11 with value: 0.6682130566242375.\n",
      "[I 2025-05-09 23:16:26,672] Trial 20 finished with value: 0.6343543027087557 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 3, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0014085514686681489}. Best is trial 11 with value: 0.6682130566242375.\n",
      "[I 2025-05-09 23:16:27,968] Trial 21 finished with value: 0.658712394771013 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.000702783860065867}. Best is trial 11 with value: 0.6682130566242375.\n",
      "[I 2025-05-09 23:16:29,213] Trial 22 finished with value: 0.6670914736252656 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0006590377526773972}. Best is trial 11 with value: 0.6682130566242375.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:30,090] Trial 23 finished with value: 0.676492024746162 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0005722162546602498}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:31,041] Trial 24 finished with value: 0.6740923178710291 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0005569585092632249}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:31,972] Trial 25 finished with value: 0.6668600580771186 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0015728007903906087}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:33,204] Trial 26 finished with value: 0.6477099259971928 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 1, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0005744400810889454}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:34,023] Trial 27 finished with value: 0.6374154120684626 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.00034199412336794767}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:34,795] Trial 28 finished with value: 0.6301264935914359 and parameters: {'embedding_dim': 768, 'hidden_dim': 64, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.1, 'lr': 0.0010619898956316985}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:35,751] Trial 29 finished with value: 0.6719341544106108 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.0022423637929396803}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:36,628] Trial 30 finished with value: 0.645236564494015 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.004346238149575035}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:37,509] Trial 31 finished with value: 0.6632822810836256 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.002601103247239675}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:16:38,765] Trial 32 finished with value: 0.6613581826452714 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.003915709631395162}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:39,670] Trial 33 finished with value: 0.6754066366979126 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.0008903830377704104}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:41,064] Trial 34 finished with value: 0.646550579942125 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 1, 'bidirectional': True, 'dropout': 0.5, 'lr': 0.002020264208669289}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:42,013] Trial 35 finished with value: 0.6723798810180192 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.0012536264888953434}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:42,879] Trial 36 finished with value: 0.6661570472326591 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 1, 'bidirectional': True, 'dropout': 0.5, 'lr': 0.00118847275716885}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:43,700] Trial 37 finished with value: 0.6197743476350442 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.00027977469602188243}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:16:44,948] Trial 38 finished with value: 0.0 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 5, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.0009682583834165094}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:45,797] Trial 39 finished with value: 0.5690498430792995 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.1, 'lr': 0.000207866952718477}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:46,647] Trial 40 finished with value: 0.6706371892971789 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 1, 'bidirectional': True, 'dropout': 0.5, 'lr': 0.0005609388723981421}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:47,574] Trial 41 finished with value: 0.6680020414503173 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.003408271397854205}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:48,350] Trial 42 finished with value: 0.6542419423306031 and parameters: {'embedding_dim': 768, 'hidden_dim': 64, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.0012633244921288562}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:49,101] Trial 43 finished with value: 0.6662289090404451 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.0019741970468994774}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:50,028] Trial 44 finished with value: 0.6528554293289979 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.0003766670088995071}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:16:51,372] Trial 45 finished with value: 0.6607002656380119 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.1, 'lr': 0.0008781137183172127}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:52,207] Trial 46 finished with value: 0.6486173862627266 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.0005244823780396626}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:16:53,453] Trial 47 finished with value: 0.6567055521250066 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.006713069666086527}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:54,295] Trial 48 finished with value: 0.6692845882561109 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.0029261614650474407}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:16:55,911] Trial 49 finished with value: 0.6533685144646257 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.1, 'lr': 0.0018195907846408296}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:16:57,090] Trial 50 finished with value: 0.5079055374894614 and parameters: {'embedding_dim': 768, 'hidden_dim': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0.5, 'lr': 0.0053453203659079235}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:58,052] Trial 51 finished with value: 0.6462554713640043 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 1, 'bidirectional': True, 'dropout': 0.5, 'lr': 0.0005852695856741774}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:58,951] Trial 52 finished with value: 0.6453717747171919 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 1, 'bidirectional': True, 'dropout': 0.5, 'lr': 0.00041224990027910236}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:16:59,899] Trial 53 finished with value: 0.6677530912204844 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 1, 'bidirectional': True, 'dropout': 0.5, 'lr': 0.0008587845533106527}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:17:00,907] Trial 54 finished with value: 0.6457140494030473 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 1, 'bidirectional': True, 'dropout': 0.5, 'lr': 0.0004884925510380261}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:17:02,320] Trial 55 finished with value: 0.6537306934501993 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 1, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0006288341239597417}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:17:03,434] Trial 56 finished with value: 0.6750348817848222 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0013531019757581563}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:17:04,715] Trial 57 finished with value: 0.6484759994493934 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0013422263431791285}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:17:05,893] Trial 58 finished with value: 0.6566329865788513 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0015453707953507285}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:17:08,054] Trial 59 finished with value: 0.5241950233913408 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.009930506663205402}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:17:09,340] Trial 60 finished with value: 0.6736394530363444 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.001093181930916859}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:17:11,095] Trial 61 finished with value: 0.6174666188321452 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 3, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0011035867383195036}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:17:12,897] Trial 62 finished with value: 0.6330023325610724 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 3, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0008231374810361105}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:17:14,547] Trial 63 finished with value: 0.6292046310872043 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 3, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0010183875041920184}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:17:15,918] Trial 64 finished with value: 0.663708402838778 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0021643614668917324}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:17:16,913] Trial 65 finished with value: 0.6544804678996229 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0016855920941103624}. Best is trial 23 with value: 0.676492024746162.\n",
      "/home/malik/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  warnings.warn(\n",
      "[I 2025-05-09 23:17:17,695] Trial 66 finished with value: 0.6042424242424242 and parameters: {'embedding_dim': 768, 'hidden_dim': 64, 'num_layers': 1, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0007063683598303638}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:17:19,134] Trial 67 finished with value: 0.6547705796580525 and parameters: {'embedding_dim': 768, 'hidden_dim': 512, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0013250002368472053}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:17:20,023] Trial 68 finished with value: 0.673535240827342 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0009641624808295209}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:17:20,997] Trial 69 finished with value: 0.6757626161495331 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.25, 'lr': 0.0007488578199123637}. Best is trial 23 with value: 0.676492024746162.\n",
      "[I 2025-05-09 23:17:22,208] Trial 70 finished with value: 0.6767570425300298 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0009057921298744007}. Best is trial 70 with value: 0.6767570425300298.\n",
      "[I 2025-05-09 23:17:23,415] Trial 71 finished with value: 0.6567028966664933 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0009499822159459394}. Best is trial 70 with value: 0.6767570425300298.\n",
      "[I 2025-05-09 23:17:24,627] Trial 72 finished with value: 0.6696436145026874 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0007483257180833775}. Best is trial 70 with value: 0.6767570425300298.\n",
      "[I 2025-05-09 23:17:26,069] Trial 73 finished with value: 0.6565629884725429 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0006450682199955118}. Best is trial 70 with value: 0.6767570425300298.\n",
      "[I 2025-05-09 23:17:27,288] Trial 74 finished with value: 0.6938786434986675 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0011093011094073127}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:28,525] Trial 75 finished with value: 0.6751471854139376 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0007820603876895806}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:30,159] Trial 76 finished with value: 0.5358809849118487 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 4, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.00045390139863342563}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:31,629] Trial 77 finished with value: 0.6803458375507778 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0007587617052501273}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:33,007] Trial 78 finished with value: 0.6768444526742091 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0008090958215292081}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:34,420] Trial 79 finished with value: 0.6915531189062921 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0007676087679195809}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:35,850] Trial 80 finished with value: 0.6737432325160938 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0006668385327564477}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:37,240] Trial 81 finished with value: 0.6713935089257127 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0007889120101213764}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:38,634] Trial 82 finished with value: 0.664437614096899 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0008195062722145929}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:40,037] Trial 83 finished with value: 0.682567838244148 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0009021730210165103}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:41,476] Trial 84 finished with value: 0.6721278588332298 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0009357374559401274}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:42,860] Trial 85 finished with value: 0.6807029099771656 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0011772296860691242}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:44,533] Trial 86 finished with value: 0.5257911307866208 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 4, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0011447047236430217}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:46,027] Trial 87 finished with value: 0.6805425531843595 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0005188723753973151}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:47,468] Trial 88 finished with value: 0.6639088089646329 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0005392200157527053}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:48,897] Trial 89 finished with value: 0.6241024046434495 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0003560933514402031}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:50,336] Trial 90 finished with value: 0.6736491852570005 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.1, 'lr': 0.0006116344537722995}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:51,795] Trial 91 finished with value: 0.6845476770719316 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0007136234542064215}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:53,194] Trial 92 finished with value: 0.5893741976349172 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.000308037350932282}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:54,631] Trial 93 finished with value: 0.6375639317879078 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.00040988211856389517}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:56,070] Trial 94 finished with value: 0.6674856475916183 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0004959806836267789}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:57,463] Trial 95 finished with value: 0.6600368989963016 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0006868164681615208}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:17:58,861] Trial 96 finished with value: 0.6754161322736536 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0015068337307582184}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:18:01,078] Trial 97 finished with value: 0.6747328509122369 and parameters: {'embedding_dim': 768, 'hidden_dim': 256, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0011919620465599902}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:18:02,721] Trial 98 finished with value: 0.565273622480667 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 4, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0010321378907965232}. Best is trial 74 with value: 0.6938786434986675.\n",
      "[I 2025-05-09 23:18:04,101] Trial 99 finished with value: 0.6669506330471616 and parameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 3, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0008504428989766986}. Best is trial 74 with value: 0.6938786434986675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'embedding_dim': 768, 'hidden_dim': 128, 'num_layers': 2, 'bidirectional': True, 'dropout': 0.25, 'lr': 0.0011093011094073127}\n"
     ]
    }
   ],
   "source": [
    "# ---- Run the Optuna Study ----\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8dcc2d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val(\n",
    "        model: LSTM,\n",
    "        optim: Adam,\n",
    "        criterion: nn.BCELoss,\n",
    "        epochs: int,\n",
    "        train_dataloader: DataLoader,\n",
    "        val_dataloader: DataLoader,\n",
    "        device\n",
    "    ):\n",
    "    best_f1 = 0\n",
    "    best_model = None\n",
    "    model.to(device)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        y_preds_list_train = []\n",
    "        y_true_list_train = []\n",
    "        for train_X, train_y in train_dataloader:\n",
    "            train_X, train_y = train_X.to(device), train_y.to(device)\n",
    "    \n",
    "            y_preds = model(train_X)\n",
    "            loss = criterion(y_preds, train_y)\n",
    "    \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "    \n",
    "            train_loss += loss.item()\n",
    "            y_preds_list_train.extend(y_preds.detach().cpu().numpy())\n",
    "            y_true_list_train.extend(train_y.detach().cpu().numpy())\n",
    "    \n",
    "        y_preds = np.array([get_prediction(pred) for pred in y_preds_list_train])\n",
    "        y_true = np.array(y_true_list_train) \n",
    "        train_f1 =f1_score(y_true, y_preds, average='weighted')\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        y_preds_list_val = []\n",
    "        y_true_list_val = []\n",
    "        with torch.no_grad():\n",
    "            for val_X, val_y in val_dataloader:\n",
    "                val_X, val_y = val_X.to(device), val_y.to(device)\n",
    "    \n",
    "                y_preds = model(val_X)\n",
    "                loss = criterion(y_preds, val_y)\n",
    "                val_loss += loss.item()\n",
    "                predicted = torch.argmax(y_preds, dim=1)\n",
    "                y_preds_list_val.extend(y_preds.detach().cpu().numpy())\n",
    "                y_true_list_val.extend(val_y.detach().cpu().numpy())\n",
    "    \n",
    "        y_preds = np.array([get_prediction(pred) for pred in y_preds_list_val])\n",
    "        y_true = np.array(y_true_list_val)\n",
    "        val_f1 = f1_score(y_true, y_preds, average='weighted')\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_model = model.state_dict()\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs}, \"\n",
    "            f\"Train Loss: {train_loss/len(train_dataloader):.4f}, \"\n",
    "            f\"Val Loss: {val_loss/len(val_dataloader):.4f}, \"\n",
    "            f\"Train F1: {train_f1:.2f}%, \"\n",
    "            f\"Val F1: {val_f1:.2f}%\"\n",
    "        )\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a9541a4a-d5d7-415d-9ba6-d2e86037b461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|                                                                           | 1/10 [00:00<00:06,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.4139, Val Loss: 0.3441, Train F1: 0.51%, Val F1: 0.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|                                                                   | 2/10 [00:01<00:04,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.2620, Val Loss: 0.3433, Train F1: 0.77%, Val F1: 0.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|                                                          | 3/10 [00:01<00:03,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.1522, Val Loss: 0.3935, Train F1: 0.89%, Val F1: 0.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|                                                  | 4/10 [00:02<00:03,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.0709, Val Loss: 0.5041, Train F1: 0.96%, Val F1: 0.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|                                          | 5/10 [00:02<00:02,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.0338, Val Loss: 0.6250, Train F1: 0.98%, Val F1: 0.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|                                 | 6/10 [00:03<00:02,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.0305, Val Loss: 0.5847, Train F1: 0.98%, Val F1: 0.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|                         | 7/10 [00:03<00:01,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.0125, Val Loss: 0.6364, Train F1: 0.99%, Val F1: 0.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|                | 8/10 [00:04<00:01,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.0032, Val Loss: 0.6664, Train F1: 1.00%, Val F1: 0.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|        | 9/10 [00:04<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.0019, Val Loss: 0.6933, Train F1: 1.00%, Val F1: 0.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:05<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.0012, Val Loss: 0.6952, Train F1: 1.00%, Val F1: 0.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = MultiLabelLSTM(\n",
    "\t\t\tvocab_size=VOCAB_SIZE,\n",
    "\t\t\tembedding_dim=study.best_trial.params['embedding_dim'],\n",
    "\t\t\thidden_dim=study.best_trial.params['hidden_dim'],\n",
    "\t\t\tnum_layers=study.best_trial.params['num_layers'],\n",
    "\t\t\tnum_classes=NUM_CLASSES,\n",
    "\t\t\tbidirectional=study.best_trial.params['bidirectional'],\n",
    "            dropout = study.best_trial.params['dropout'],\n",
    "\t\t).to(DEVICE)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = Adam(model.parameters(), lr=study.best_trial.params['lr'])\n",
    "params = train_val(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    epochs = 10,\n",
    "    train_dataloader = train_loader,\n",
    "    val_dataloader = val_loader,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6c1dfb",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ad40d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8363a59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(\n",
    "\t\tmodel: LSTM,\n",
    "\t\toptim: Adam,\n",
    "\t\tcriterion: nn.BCEWithLogitsLoss,\n",
    "\t\ttest_dataloader: DataLoader,\n",
    "\t\tdevice\n",
    "    ):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    y_preds_list = []\n",
    "    y_true_list = []\n",
    "    with torch.no_grad():\n",
    "        for test_X, test_y in test_dataloader:\n",
    "            test_X, test_y = test_X.to(device), test_y.to(device)\n",
    "    \n",
    "            y_preds = model(test_X)\n",
    "            y_preds_list.extend(y_preds.detach().cpu().numpy())\n",
    "            y_true_list.extend(test_y.detach().cpu().numpy())\n",
    "            loss = criterion(y_preds, test_y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "        y_preds_list = [get_prediction(pred) for pred in y_preds_list]\n",
    "    print(\n",
    "        f\"test Loss: {test_loss/len(test_dataloader):.4f}, \"\n",
    "        f\"test Acc: {accuracy_score(y_true_list, y_preds_list)}%\"\n",
    "    )\n",
    "    return np.array(y_preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b3b4e587-bb8f-4531-93db-3a39b50a3666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5416, test Acc: 0.6804308797127468%\n"
     ]
    }
   ],
   "source": [
    "best_model = MultiLabelLSTM(\n",
    "\t\t\tvocab_size=VOCAB_SIZE,\n",
    "\t\t\tembedding_dim=study.best_trial.params['embedding_dim'],\n",
    "\t\t\thidden_dim=study.best_trial.params['hidden_dim'],\n",
    "\t\t\tnum_layers=study.best_trial.params['num_layers'],\n",
    "\t\t\tnum_classes=NUM_CLASSES,\n",
    "\t\t\tbidirectional=study.best_trial.params['bidirectional'],\n",
    "            dropout = study.best_trial.params['dropout'],\n",
    "\t\t)\n",
    "best_model.load_state_dict(params)\n",
    "y_preds=test(best_model, optimizer, criterion, test_loader, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9ca433bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74       131\n",
      "           1       0.63      0.62      0.62        87\n",
      "           2       0.66      0.50      0.57        82\n",
      "           3       0.83      0.76      0.79       257\n",
      "\n",
      "   micro avg       0.76      0.69      0.72       557\n",
      "   macro avg       0.72      0.65      0.68       557\n",
      "weighted avg       0.75      0.69      0.72       557\n",
      " samples avg       0.69      0.69      0.69       557\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malik/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, y_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
